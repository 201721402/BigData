{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86977c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import Row\n",
    "myConf=pyspark.SparkConf()\n",
    "spark = pyspark.sql.SparkSession.builder\\\n",
    "        .master(\"local\")\\\n",
    "        .appName(\"myApp\")\\\n",
    "        .config(conf=myConf)\\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afeb48d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Competition: string (nullable = true)\n",
      " |-- Year: long (nullable = true)\n",
      " |-- Team: string (nullable = true)\n",
      " |-- Number: string (nullable = true)\n",
      " |-- Position: string (nullable = true)\n",
      " |-- FullName: string (nullable = true)\n",
      " |-- Club: string (nullable = true)\n",
      " |-- ClubCountry: string (nullable = true)\n",
      " |-- DateOfBirth: string (nullable = true)\n",
      " |-- IsCaptain: boolean (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "r=requests.get(\"https://raw.githubusercontent.com/jokecamp/FootballData/master/World%20Cups/all-world-cup-players.json\")\n",
    "wc=r.json()\n",
    "wcDf = spark.createDataFrame(Row(**x) for x in wc)\n",
    "wcDf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34651b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+----+\n",
      "|                Club|     Team|Year|\n",
      "+--------------------+---------+----+\n",
      "|Club AtlÃ©tico Ta...|Argentina|1930|\n",
      "+--------------------+---------+----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "wcDf.createOrReplaceTempView(\"wc\")\n",
    "spark.sql(\"select Club,Team,Year from wc\").show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e0d0268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+---------+----+\n",
      "|    FullName|                Club|     Team|Year|\n",
      "+------------+--------------------+---------+----+\n",
      "|Ãngel Bossio|Club AtlÃ©tico Ta...|Argentina|1930|\n",
      "+------------+--------------------+---------+----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "wcPlayers=spark.sql(\"select FullName,Club,Team,Year from wc\")\n",
    "wcPlayers.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "665dc074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Table(name='wc', database=None, description=None, tableType='TEMPORARY', isTemporary=True)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#여태까지 등록된 테이블 출력\n",
    "spark.catalog.listTables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8245cd95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full name: Ãngel Bossio\n",
      "Full name: Juan Botasso\n",
      "Full name: Roberto Cherro\n",
      "Full name: Alberto Chividini\n",
      "Full name: \n"
     ]
    }
   ],
   "source": [
    "#만들어놓은 sql에서 첫번째 열만 가져오자!\n",
    "namesRdd=wcPlayers.rdd.map(lambda x: \"Full name: \"+x[0])\n",
    "for e in namesRdd.take(5):\n",
    "    print (e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51e99a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#아래같이 item이 리스트로 묶인 것은 좋지 않다. 분리해야한다. \n",
    "bucketDf=spark.createDataFrame([[1,[\"orange\", \"apple\", \"pineapple\"]],\n",
    "                                [2,[\"watermelon\",\"apple\",\"bananas\"]]],\n",
    "                               [\"bucketId\",\"items\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c013619d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#explode []안에 분리해야한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23603294",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+\n",
      "|bucketId|      item|\n",
      "+--------+----------+\n",
      "|       1|    orange|\n",
      "|       1|     apple|\n",
      "|       1| pineapple|\n",
      "|       2|watermelon|\n",
      "|       2|     apple|\n",
      "|       2|   bananas|\n",
      "+--------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import explode\n",
    "bDf=bucketDf.select(bucketDf.bucketId, explode(bucketDf.items).alias('item'))\n",
    "bDf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a56dbd72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+\n",
      "|      item|itemId|\n",
      "+----------+------+\n",
      "|    orange|    F1|\n",
      "|          |    F2|\n",
      "| pineapple|    F3|\n",
      "|watermelon|    F4|\n",
      "|   bananas|    F5|\n",
      "+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fDf=spark.createDataFrame([[\"orange\", \"F1\"],\n",
    "                            [\"\", \"F2\"],\n",
    "                            [\"pineapple\",\"F3\"],\n",
    "                            [\"watermelon\",\"F4\"],\n",
    "                            [\"bananas\",\"F5\"]],\n",
    "                            [\"item\",\"itemId\"])\n",
    "fDf.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4026ac7a",
   "metadata": {},
   "source": [
    "### join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eb35dfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "joinDf=fDf.join(bDf, fDf.item==bDf.item, \"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b2f25574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+--------+\n",
      "|itemId|      item|bucketId|\n",
      "+------+----------+--------+\n",
      "|    F5|   bananas|       2|\n",
      "|    F1|    orange|       1|\n",
      "|    F3| pineapple|       1|\n",
      "|    F4|watermelon|       2|\n",
      "+------+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "joinDf.select(fDf.itemId,fDf.item,bDf.bucketId).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142ce5ec",
   "metadata": {},
   "source": [
    "## 문제 S-1: 네트워크에 불법적으로 침입하는 사용자의 분석\n",
    "\n",
    "### 문제\n",
    "\n",
    "네트워크에 불법적으로 침입하는 시도는 허용되어서는 안된다.\n",
    "1998년 MIT Lincoln Labs에서 DARPA Intrusion Detection Evaluation Program을 연구하였다.\n",
    "이 데이터의 일부가 1999년 KDD로 만들어져 배포되고 있다.\n",
    "https://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html\n",
    "\n",
    "### 해결\n",
    "\n",
    "마지막 행에 attack의 유형이 구분되어 있다. 네트워크 침입 유형의 특징을 분석해 보자.\n",
    "탐지예방 모델을 구축할 수 있다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "53c3273f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "_url = 'http://kdd.ics.uci.edu/databases/kddcup99/kddcup.data_10_percent.gz'\n",
    "_fname = os.path.join(os.getcwd(),'data','kddcup.data_10_percent.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "140a1d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlretrieve\n",
    "\n",
    "if(not os.path.exists(_fname)):\n",
    "    print (\"{} data does not exist! retrieving..\".format(_fname))\n",
    "    _f=urlretrieve(_url,_fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476ba1f3",
   "metadata": {},
   "source": [
    "RDD 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fb35d9cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "494021"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_rdd = spark.sparkContext.textFile(_fname)\n",
    "_rdd.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "459978c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0,tcp,http,SF,181,5450,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,8,8,0.00,0.00,0.00,0.00,1.00,0.00,0.00,9,9,1.00,0.00,0.11,0.00,0.00,0.00,0.00,0.00,normal.']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_rdd.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "087ff282",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['0',\n",
       "  'tcp',\n",
       "  'http',\n",
       "  'SF',\n",
       "  '181',\n",
       "  '5450',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '1',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '8',\n",
       "  '8',\n",
       "  '0.00',\n",
       "  '0.00',\n",
       "  '0.00',\n",
       "  '0.00',\n",
       "  '1.00',\n",
       "  '0.00',\n",
       "  '0.00',\n",
       "  '9',\n",
       "  '9',\n",
       "  '1.00',\n",
       "  '0.00',\n",
       "  '0.11',\n",
       "  '0.00',\n",
       "  '0.00',\n",
       "  '0.00',\n",
       "  '0.00',\n",
       "  '0.00',\n",
       "  'normal.']]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_allRdd=_rdd.map(lambda x: x.split(','))\n",
    "_allRdd.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9057508e",
   "metadata": {},
   "source": [
    "### 정상, 공격 건수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a0ad45ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "_normalRdd=_allRdd.filter(lambda x: x[41]==\"normal.\")\n",
    "_attackRdd=_allRdd.filter(lambda x: x[41]!=\"normal.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935547d2",
   "metadata": {},
   "source": [
    "### attack별 건수\n",
    "\n",
    "**attack 종류**는 41번째 열에 구분되어 있다. 총 494,021건을 정상 'noraml'과 나머지는 'attack'으로 구분한다.\n",
    "'attack'은 크게 4종류로 나눈다. DOS는 서비스 거부, R2L 원격침입, U2R은 루트권한침입, probing은 탐지이다.\n",
    "\n",
    "attack 4종류 | 설명 | 41번째 열\n",
    "-----|-----|-----\n",
    "DOS | denial-of-service, e.g. syn flood | back, land, neptune, pod, smurf, teardrop\n",
    "R2L | unauthorized access from a remote machine | ftp_write, guess_passwd, imap, multihop, phf, spy, warezclient, warezmaster\n",
    "U2R | unauthorized access to local superuser (root) privileges | buffer_overflow, loadmodule, perl, rootkit\n",
    "probing | surveillance and other probing | ipsweep, nmap, portsweep, satan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a69d763",
   "metadata": {},
   "source": [
    "열41에 대해 건수를 세어보자.\n",
    "```reduceByKey()```는 인자로 '함수'가 필요. 키별로 '함수를 사용해서' 계산한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "219847d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('normal.', 97278),\n",
       " ('buffer_overflow.', 30),\n",
       " ('loadmodule.', 9),\n",
       " ('perl.', 3),\n",
       " ('neptune.', 107201),\n",
       " ('smurf.', 280790),\n",
       " ('guess_passwd.', 53),\n",
       " ('pod.', 264),\n",
       " ('teardrop.', 979),\n",
       " ('portsweep.', 1040),\n",
       " ('ipsweep.', 1247),\n",
       " ('land.', 21),\n",
       " ('ftp_write.', 8),\n",
       " ('back.', 2203),\n",
       " ('imap.', 12),\n",
       " ('satan.', 1589),\n",
       " ('phf.', 4),\n",
       " ('nmap.', 231),\n",
       " ('multihop.', 7),\n",
       " ('warezmaster.', 20),\n",
       " ('warezclient.', 1020),\n",
       " ('spy.', 2),\n",
       " ('rootkit.', 10)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_41 = _allRdd.map(lambda x: (x[41], 1))\n",
    "_41.reduceByKey(lambda x,y: x+y).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad6ac74",
   "metadata": {},
   "source": [
    "## DataFrame 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "87137089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- duration: long (nullable = true)\n",
      " |-- protocol: string (nullable = true)\n",
      " |-- service: string (nullable = true)\n",
      " |-- flag: string (nullable = true)\n",
      " |-- src_bytes: long (nullable = true)\n",
      " |-- dst_bytes: long (nullable = true)\n",
      " |-- attack: string (nullable = true)\n",
      "\n",
      "+--------+--------+-------+----+---------+---------+-------+\n",
      "|duration|protocol|service|flag|src_bytes|dst_bytes| attack|\n",
      "+--------+--------+-------+----+---------+---------+-------+\n",
      "|       0|     tcp|   http|  SF|      181|     5450|normal.|\n",
      "|       0|     tcp|   http|  SF|      239|      486|normal.|\n",
      "|       0|     tcp|   http|  SF|      235|     1337|normal.|\n",
      "|       0|     tcp|   http|  SF|      219|     1337|normal.|\n",
      "|       0|     tcp|   http|  SF|      217|     2032|normal.|\n",
      "+--------+--------+-------+----+---------+---------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Row\n",
    "\n",
    "_csv = _rdd.map(lambda l: l.split(\",\"))\n",
    "_csvRdd = _csv.map(lambda p: \n",
    "    Row(\n",
    "        duration=int(p[0]), \n",
    "        protocol=p[1],\n",
    "        service=p[2],\n",
    "        flag=p[3],\n",
    "        src_bytes=int(p[4]),\n",
    "        dst_bytes=int(p[5]),\n",
    "        attack=p[41]\n",
    "    )\n",
    ")\n",
    "_df=spark.createDataFrame(_csvRdd)\n",
    "_df.printSchema()\n",
    "_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327473dc",
   "metadata": {},
   "source": [
    "### attack 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a6bc2b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- duration: long (nullable = true)\n",
      " |-- protocol: string (nullable = true)\n",
      " |-- service: string (nullable = true)\n",
      " |-- flag: string (nullable = true)\n",
      " |-- src_bytes: long (nullable = true)\n",
      " |-- dst_bytes: long (nullable = true)\n",
      " |-- attack: string (nullable = true)\n",
      " |-- attackB: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "attack_udf = udf(lambda x: \"normal\" if x ==\"normal.\" else \"attack\", StringType())\n",
    "myDf=_df.withColumn(\"attackB\", attack_udf(_df.attack))\n",
    "myDf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5b5309f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- duration: long (nullable = true)\n",
      " |-- protocol: string (nullable = true)\n",
      " |-- service: string (nullable = true)\n",
      " |-- flag: string (nullable = true)\n",
      " |-- src_bytes: long (nullable = true)\n",
      " |-- dst_bytes: long (nullable = true)\n",
      " |-- attack: string (nullable = true)\n",
      " |-- attackB: string (nullable = true)\n",
      " |-- attack5: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# attack 세분화해주는 함수 \n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "def classify41(s):\n",
    "    _5=\"\"\n",
    "    if s==\"normal.\":\n",
    "        _5=\"normal\"\n",
    "    elif s==\"back.\" or s==\"land.\" or s==\"neptune.\" or s==\"pod.\" or s==\"smurf.\" or s==\"teardrop.\":\n",
    "        _5=\"dos\"\n",
    "    elif s==\"ftp_write.\" or s==\"guess_passwd.\" or s==\"imap.\" or s==\"multihop.\" or s==\"phf.\" or\\\n",
    "        s==\"spy.\" or s==\"warezclient.\" or s==\"warezmaster.\":\n",
    "        _5=\"r2l\"\n",
    "    elif s==\"buffer_overflow.\" or s==\"loadmodule.\" or s==\"perl.\" or s==\"rootkit.\":\n",
    "        _5=\"u2r\"\n",
    "    elif s==\"ipsweep.\" or s==\"nmap.\" or s==\"portsweep.\" or s==\"satan.\":\n",
    "        _5=\"probing\"\n",
    "    return _5\n",
    "\n",
    "attack5_udf = udf(classify41, StringType())\n",
    "myDf=myDf.withColumn(\"attack5\", attack5_udf(_df.attack))\n",
    "myDf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "def9381a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+-------+----+---------+---------+-------+-------+-------+\n",
      "|duration|protocol|service|flag|src_bytes|dst_bytes| attack|attackB|attack5|\n",
      "+--------+--------+-------+----+---------+---------+-------+-------+-------+\n",
      "|       0|     tcp|   http|  SF|      181|     5450|normal.| normal| normal|\n",
      "|       0|     tcp|   http|  SF|      239|      486|normal.| normal| normal|\n",
      "|       0|     tcp|   http|  SF|      235|     1337|normal.| normal| normal|\n",
      "|       0|     tcp|   http|  SF|      219|     1337|normal.| normal| normal|\n",
      "|       0|     tcp|   http|  SF|      217|     2032|normal.| normal| normal|\n",
      "+--------+--------+-------+----+---------+---------+-------+-------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "myDf.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5434f99d",
   "metadata": {},
   "source": [
    "### attack, normal 특징 분석\n",
    "#### groupBy 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f31d407e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+\n",
      "|attack5| count|\n",
      "+-------+------+\n",
      "|probing|  4107|\n",
      "|    u2r|    52|\n",
      "| normal| 97278|\n",
      "|    r2l|  1126|\n",
      "|    dos|391458|\n",
      "+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "myDf.groupBy('attack5').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cae3cee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+\n",
      "|protocol| count|\n",
      "+--------+------+\n",
      "|     tcp|190065|\n",
      "|     udp| 20354|\n",
      "|    icmp|283602|\n",
      "+--------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "myDf.groupBy(\"protocol\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7089735b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------+-----+\n",
      "|attackB|  icmp|   tcp|  udp|\n",
      "+-------+------+------+-----+\n",
      "| normal|  1288| 76813|19177|\n",
      "| attack|282314|113252| 1177|\n",
      "+-------+------+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#attackB에 protocol별로 보기\n",
    "myDf.groupBy('attackB').pivot('protocol').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cc311573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+------------------+\n",
      "|attack5|              icmp|               tcp|               udp|\n",
      "+-------+------------------+------------------+------------------+\n",
      "|probing|10.700793650793651| 261454.6003016591|25.235897435897435|\n",
      "|    u2r|              null| 960.8979591836735|13.333333333333334|\n",
      "| normal| 91.47049689440993|1439.3120305156679| 98.01220211711947|\n",
      "|    r2l|              null|271972.57460035523|              null|\n",
      "|    dos| 936.2672084368129| 1090.303422435458|              28.0|\n",
      "+-------+------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#attackB에 protocol별로 보기 src_bytes의 평균\n",
    "myDf.groupBy('attack5').pivot('protocol').avg('src_bytes').show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6a9903e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|attack5|       avg(duration)|\n",
      "+-------+--------------------+\n",
      "|probing|   485.0299488677867|\n",
      "|    u2r|    80.9423076923077|\n",
      "| normal|  216.65732231336992|\n",
      "|    r2l|   559.7522202486679|\n",
      "|    dos|7.254929008986916E-4|\n",
      "+-------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "myDf.groupBy('attack5').avg('duration').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0be1dfc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+-------+---+\n",
      "|attackB|icmp|    tcp|udp|\n",
      "+-------+----+-------+---+\n",
      "| normal|   0|5134218|516|\n",
      "| attack|   0|5155468| 74|\n",
      "+-------+----+-------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#F를 사용해서 목적지의 최대값을 구하자 \n",
    "from pyspark.sql import functions as F\n",
    "myDf.groupBy('attackB').pivot('protocol').agg(F.max('dst_bytes')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b579b084",
   "metadata": {},
   "source": [
    " ```duration>1000)```, ```dst_bytes==0```인 경우의 건수를 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ffa2c9ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|protocol|count|\n",
      "+--------+-----+\n",
      "|     tcp|  139|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "myDf.select(\"protocol\", \"duration\", \"dst_bytes\")\\\n",
    "    .filter(_df.duration>1000)\\\n",
    "    .filter(_df.dst_bytes==0)\\\n",
    "    .groupBy(\"protocol\")\\\n",
    "    .count()\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2037674f",
   "metadata": {},
   "source": [
    "### SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "275f3307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+\n",
      "|duration|dst_bytes|\n",
      "+--------+---------+\n",
      "|    5057|        0|\n",
      "|    5059|        0|\n",
      "|    5051|        0|\n",
      "|    5056|        0|\n",
      "|    5051|        0|\n",
      "+--------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_df.registerTempTable(\"_tab\")\n",
    "tcp_interactions = spark.sql(\n",
    "\"\"\"\n",
    "    SELECT duration, dst_bytes FROM _tab\n",
    "    WHERE protocol = 'tcp' AND duration > 1000 AND dst_bytes = 0\n",
    "\"\"\")\n",
    "tcp_interactions.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b7371dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration: 5057, Dest. bytes: 0\n",
      "Duration: 5043, Dest. bytes: 0\n",
      "Duration: 5046, Dest. bytes: 0\n",
      "Duration: 5051, Dest. bytes: 0\n",
      "Duration: 5057, Dest. bytes: 0\n",
      "Duration: 5063, Dest. bytes: 0\n",
      "Duration: 42448, Dest. bytes: 0\n",
      "Duration: 40121, Dest. bytes: 0\n",
      "Duration: 31709, Dest. bytes: 0\n",
      "Duration: 30619, Dest. bytes: 0\n",
      "Duration: 22616, Dest. bytes: 0\n",
      "Duration: 21455, Dest. bytes: 0\n",
      "Duration: 13998, Dest. bytes: 0\n",
      "Duration: 12933, Dest. bytes: 0\n"
     ]
    }
   ],
   "source": [
    "tcp_interactions_out = tcp_interactions.rdd\\\n",
    "    .map(lambda p: \"Duration: {}, Dest. bytes: {}\".format(p.duration, p.dst_bytes))\n",
    "\n",
    "for i,ti_out in enumerate(tcp_interactions_out.collect()):\n",
    "    if(i%10==0):\n",
    "        print(ti_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe6ffce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
